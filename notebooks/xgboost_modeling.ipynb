{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IRONMAN\\miniconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To Visualize Data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# To Train our data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# To evaluate end result we have\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/21 01:14:04 INFO mlflow.tracking.fluent: Experiment with name 'different machine learning algorithms' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, \"../scripts\")\n",
    "from ml_processors import ML_Processor as MLP\n",
    "from models import ML_Models\n",
    "\n",
    "mlp = MLP()\n",
    "mlm = ML_Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data =  pd.read_csv('../data/facebook_data.csv')\n",
    "ch_data =  pd.read_csv('../data/chrome_data.csv')\n",
    "cm_data =  pd.read_csv('../data/chrome_mobile_webview_data.csv')\n",
    "pt5_data =  pd.read_csv('../data/platform_5.csv')\n",
    "pt6_data =  pd.read_csv('../data/platform_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# separating categorical and numerical variables\n",
    "\n",
    "cat2, num2 = mlp.sep_cat_num(fb_data)\n",
    "cat3, num3 = mlp.sep_cat_num(ch_data)\n",
    "cat4, num4 = mlp.sep_cat_num(cm_data)\n",
    "cat5, num5 = mlp.sep_cat_num(pt5_data)\n",
    "cat6, num6 = mlp.sep_cat_num(pt6_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagories successfully labeled\n",
      "Data successfully scaled\n",
      "target and features separated\n",
      "data successfully splitted\n"
     ]
    }
   ],
   "source": [
    "def processor_pipe(categories):\n",
    "    pipe_1 = Pipeline(\n",
    "        steps=[\n",
    "            (\"label categories\", FunctionTransformer(mlp.cat_labeler, kw_args={\"cat_cols\": categories})),\n",
    "            (\"scale data\", FunctionTransformer(mlp.scaler)),\n",
    "            (\"separate target and features\", FunctionTransformer(mlp.target_feature, kw_args={\"f_r\": [0, 6], \"t\":-1})),\n",
    "            (\"divide dataset\", FunctionTransformer(mlp.set_splitter, kw_args={\"test\": 0.1, \"val\":0.2, \"rand_state\":8})),      \n",
    "            ])\n",
    "    return pipe_1\n",
    "\n",
    "pipe_1 = processor_pipe(cat2)\n",
    "pipe_2 = processor_pipe(cat5)\n",
    "\n",
    "sets = pipe_1.fit_transform(fb_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagories successfully labeled\n",
      "Data successfully scaled\n",
      "target and features separated\n",
      "data successfully splitted\n"
     ]
    }
   ],
   "source": [
    "sets2 = pipe_1.fit_transform(ch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagories successfully labeled\n",
      "Data successfully scaled\n",
      "target and features separated\n",
      "data successfully splitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sets3 = pipe_1.fit_transform(cm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagories successfully labeled\n",
      "Data successfully scaled\n",
      "target and features separated\n",
      "data successfully splitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sets4 = pipe_2.fit_transform(pt5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagories successfully labeled\n",
      "Data successfully scaled\n",
      "target and features separated\n",
      "data successfully splitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sets5 = pipe_2.fit_transform(pt6_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "        learning_rate =0.08,\n",
    "        n_estimators=1000,\n",
    "        eval_metric='rmse',\n",
    "        )\n",
    "kfold_validation=KFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of fb_data\n",
      "\n",
      "[0.53125    0.51612903 0.35483871 0.58064516 0.51612903]\n",
      "0.4997983870967742 \n",
      "\n",
      "#################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlm.cross_val(fb_data, model, globals(), kfold_validation, [0, 6], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of ch_data\n",
      "\n",
      "[0.46043165 0.55395683 0.43884892 0.49640288 0.5323741 ]\n",
      "0.49640287769784164 \n",
      "\n",
      "#################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlm.cross_val(ch_data, model, globals(), kfold_validation, [0, 6], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of cm_data\n",
      "\n",
      "[0.41304348 0.47826087 0.51111111 0.62222222 0.66666667]\n",
      "0.5382608695652173 \n",
      "\n",
      "#################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlm.cross_val(cm_data, model, globals(), kfold_validation, [0, 6], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of pt5_data\n",
      "\n",
      "[0.51219512 0.45714286 0.46938776 0.49795918 0.51020408]\n",
      "0.489377799900448 \n",
      "\n",
      "#################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlm.cross_val(pt5_data, model, globals(), kfold_validation, [0, 6], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of pt6_data\n",
      "\n",
      "[0.75       0.75       0.66666667 0.33333333 0.33333333]\n",
      "0.5666666666666667 \n",
      "\n",
      "#################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlm.cross_val(pt6_data, model, globals(), kfold_validation, [0, 6], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model\n",
    "\n",
    "model = mlm.xgb_model(sets[0], sets[1], sets[2], sets[3])\n",
    "model2 = mlm.xgb_model(sets2[0], sets2[1], sets2[2], sets2[3])\n",
    "model3 = mlm.xgb_model(sets3[0], sets3[1], sets3[2], sets3[3])\n",
    "model4 = mlm.xgb_model(sets4[0], sets4[1], sets4[2], sets4[3])\n",
    "model5 = mlm.xgb_model(sets5[0], sets5[1], sets5[2], sets5[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy is:  0.625\n",
      "the loss function is:  binary:logistic\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\IRONMAN\\10\\10x\\abtest-mlops\\notebooks\\xgboost_modeling.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/xgboost_modeling.ipynb#ch0000012?line=0'>1</a>\u001b[0m mlm\u001b[39m.\u001b[39;49mevaluate_model(model, fb_data, sets[\u001b[39m2\u001b[39;49m], sets[\u001b[39m3\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mXGBoost\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mglobals\u001b[39;49m())\n",
      "File \u001b[1;32mc:\\Users\\IRONMAN\\10\\10x\\abtest-mlops\\notebooks\\../scripts\\models.py:53\u001b[0m, in \u001b[0;36mML_Models.evaluate_model\u001b[1;34m(self, model, df, x_test, y_test, alg, namespace)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/../scripts/models.py?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe model accuracy is: \u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n\u001b[0;32m     <a href='file:///c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/../scripts/models.py?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mthe loss function is: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mobjective)\n\u001b[1;32m---> <a href='file:///c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/../scripts/models.py?line=52'>53</a>\u001b[0m MLflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39;49m\u001b[39maccuracy for \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49mdf_name, accuracy) \u001b[39m#metric logging\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/../scripts/models.py?line=54'>55</a>\u001b[0m MLflow\u001b[39m.\u001b[39msklearn\u001b[39m.\u001b[39mlog_model(model, \u001b[39m\"\u001b[39m\u001b[39mmodel for \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdf_name) \u001b[39m#model logging\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/IRONMAN/10/10x/abtest-mlops/notebooks/../scripts/models.py?line=56'>57</a>\u001b[0m sorted_idx \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfeature_importances_\u001b[39m.\u001b[39margsort()\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "mlm.evaluate_model(model, fb_data, sets[2], sets[3], \"XGBoost\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm.evaluate_model(model2, ch_data, sets2[2], sets2[3], \"XGBoost\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm.evaluate_model(model3, cm_data, sets3[2], sets3[3], \"XGBoost\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm.evaluate_model(model4, pt5_data, sets4[2], sets4[3], \"XGBoost\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm.evaluate_model(model5, pt6_data, sets5[2], sets5[3], \"XGBoost\", globals())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b997b5b8794c030e25a28be498e8226ee8897df85ede9190db777bdc9cc75be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
